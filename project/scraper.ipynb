{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping site using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up Web Driver\n",
    "# options = Options()\n",
    "# options.add_argument(\"--headless=new\")\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# driver.get('https://guide.wisc.edu/courses/')\n",
    "\n",
    "# # Initializing empty dict for class dict \n",
    "# major_class_dict = {}\n",
    "\n",
    "# course_list = driver.find_element(By.ID, \"atozindex\")\n",
    "# subjects = course_list.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# # Gather all the URLs first\n",
    "# links = [link.get_attribute('href') for link in subjects]\n",
    "# names = [subject.text for subject in subjects]\n",
    "\n",
    "# num_subjects = len(subjects)\n",
    "\n",
    "# # Now visit each URL directly\n",
    "# for i in range(num_subjects):\n",
    "#     class_list = []\n",
    "#     name = names[i].split(' (')[0]\n",
    "#     print(name)\n",
    "#     driver.get(links[i])\n",
    "#     classes = WebDriverWait(driver, 20, ignored_exceptions=(NoSuchElementException, StaleElementReferenceException)).until(EC.presence_of_element_located((By.CLASS_NAME,  \"sc_sccoursedescs\")))\n",
    "#     titles = classes.find_elements(By.CLASS_NAME, \"courseblockcode\")\n",
    "#     credits = classes.find_elements(By.CLASS_NAME, \"courseblockcredits\")\n",
    "#     courses = classes.find_elements(By.CLASS_NAME,  \"courseblock\")\n",
    "#     num_courses = len(courses)\n",
    "#     for j in range(num_courses):\n",
    "#         class_dict = {}\n",
    "#         class_dict['class'] = titles[j].text\n",
    "#         class_dict['credits'] = int(credits[j].text[:1])\n",
    "\n",
    "#         details = courses[j].find_elements(By.CLASS_NAME, \"courseblockextra\")\n",
    "#         num_details = len(details)\n",
    "#         class_details = {}\n",
    "#         for k in range(num_details):\n",
    "#             inner_html = details[k].get_attribute('innerHTML')\n",
    "#             soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "#             text = soup.get_text().split(': ')\n",
    "#             label = text[0]\n",
    "#             info = text[1]\n",
    "#             if re.search('\\u200b|\\xa0', info):\n",
    "#                 info = info.replace('\\u200b', '').replace('\\xa0', ' ')\n",
    "#             class_details[label] = info\n",
    "#         class_dict['class info'] = class_details\n",
    "#         class_list.append(class_dict)\n",
    "#     major_class_dict[name] = class_list\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = major_class_dict\n",
    "# # Open a new CSV file for writing\n",
    "# with open('courses.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the header\n",
    "#     writer.writerow(['Department', 'Class', 'Credits', 'Requisites',  'Course Designation', 'Repeatable for Credit', 'Last Taught'])\n",
    "\n",
    "#     # Iterate over the departments and their courses\n",
    "#     for department, courses in data.items():\n",
    "#         for course in courses:\n",
    "#             class_info = course['class info']\n",
    "#             # Extract data, providing default values if any key is missing\n",
    "#             requisites = class_info.get('Requisites', '')\n",
    "#             repeatable = class_info.get('Repeatable for Credit', '')\n",
    "#             last_taught = class_info.get('Last Taught', '')\n",
    "#             course_designation = class_info.get('Course Designation', '')\n",
    "\n",
    "#             # Write the data to the CSV file\n",
    "#             writer.writerow([department, course['class'], course['credits'], requisites, course_designation, repeatable, last_taught])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping site using Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base URL\n",
    "# base_url = 'https://guide.wisc.edu'\n",
    "# start_url = 'https://guide.wisc.edu/courses/'\n",
    "\n",
    "# # Fetch main page content\n",
    "# response = requests.get(start_url)\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# # Initializing empty dict for class dict \n",
    "# major_class_dict = {}\n",
    "\n",
    "# # Extract subjects\n",
    "# subjects = soup.select('#atozindex a')\n",
    "\n",
    "# # Loop through subjects\n",
    "# for subject in subjects:\n",
    "#     class_list = []\n",
    "#     subject_url = base_url + subject['href']\n",
    "#     subject_name = subject.text.split(' (')[0]\n",
    "    \n",
    "#     print(subject_name)\n",
    "    \n",
    "#     # Get subject page content\n",
    "#     subject_response = requests.get(subject_url)\n",
    "#     subject_soup = BeautifulSoup(subject_response.content, 'html.parser')\n",
    "    \n",
    "#     # Extract class details\n",
    "#     courses = subject_soup.select('.courseblock')\n",
    "    \n",
    "#     for course in courses:\n",
    "#         class_dict = {}\n",
    "#         title = course.select_one('.courseblockcode').text\n",
    "#         if re.search('\\u200b|\\xa0', title):\n",
    "#             title = title.replace('\\u200b', '').replace('\\xa0', ' ')\n",
    "#         credit = course.select_one('.courseblockcredits').text\n",
    "        \n",
    "#         class_dict['class'] = title\n",
    "#         class_dict['credits'] = int(credit[:1])\n",
    "        \n",
    "#         details = course.select('.courseblockextra')\n",
    "#         class_details = {}\n",
    "        \n",
    "#         for detail in details:\n",
    "#             text = detail.text.split(': ')\n",
    "#             label = text[0]\n",
    "#             info = text[1]\n",
    "            \n",
    "#             if re.search('\\u200b|\\xa0', info):\n",
    "#                 info = info.replace('\\u200b', '').replace('\\xa0', ' ')\n",
    "#             class_details[label] = info\n",
    "        \n",
    "#         class_dict['class info'] = class_details\n",
    "#         class_list.append(class_dict)\n",
    "    \n",
    "#     major_class_dict[subject_name] = class_list\n",
    "\n",
    "## Writing dictionary to CSV\n",
    "# data = major_class_dict\n",
    "# # Open a new CSV file for writing\n",
    "# with open('allcourses.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the header\n",
    "#     writer.writerow(['Department', 'Class', 'Credits', 'Requisites',  'Course Designation', 'Repeatable for Credit', 'Last Taught'])\n",
    "\n",
    "#     # Iterate over the departments and their courses\n",
    "#     for department, courses in data.items():\n",
    "#         for course in courses:\n",
    "#             class_info = course['class info']\n",
    "#             # Extract data, providing default values if any key is missing\n",
    "#             requisites = class_info.get('Requisites', '')\n",
    "#             repeatable = class_info.get('Repeatable for Credit', '')\n",
    "#             last_taught = class_info.get('Last Taught', '')\n",
    "#             course_designation = class_info.get('Course Designation', '')\n",
    "\n",
    "#             # Write the data to the CSV file\n",
    "#             writer.writerow([department, course['class'], course['credits'], requisites, course_designation, repeatable, last_taught])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = pd.read_csv('allcourses.csv')\n",
    "# requisites = full_df['Requisites']\n",
    "# for requisite in requisites:\n",
    "#     try:\n",
    "#         print(requisite)\n",
    "#         reqs = re.split(r'[,.;]', requisite)\n",
    "#         reqs = [req.strip() for req in reqs]\n",
    "#         print(reqs)\n",
    "#     except TypeError as e:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = pd.read_csv('allcourses.csv')\n",
    "# df = full_df[full_df['Last Taught'].str.slice(-4) >= str(datetime.datetime.now().year-3)]\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.to_csv('cleanedallcourses.csv')\n",
    "# # df[df['Department']=='Industrial and Systems Engineering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_url = 'https://guide.wisc.edu/explore-majors/'\n",
    "# base_url = 'https://guide.wisc.edu'\n",
    "\n",
    "# response = requests.get(start_url)\n",
    "\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# items = soup.select_one('#filter-items')\n",
    "# programs = items.select('li a')\n",
    "# computer = 'Computer Sciences, B.S.'\n",
    "# ie = 'Industrial Engineering, B.S.'\n",
    "# math = 'Mathematics, B.S.'\n",
    "\n",
    "# classes = [ie, math, computer]\n",
    "# #,            ie, computer]\n",
    "\n",
    "# for program in programs:\n",
    "#     title = program.select_one('.title').text\n",
    "#     if title not in classes:\n",
    "#         continue\n",
    "#     print(title)\n",
    "#     # testing with only BS degrees first\n",
    "#     # if not re.search(r'', title):\n",
    "#     # if not re.search(r'\\s*B\\.S\\.\\s*', title):\n",
    "#         # continue\n",
    "#     program_url = base_url + program['href']\n",
    "#     program_response = requests.get(program_url)\n",
    "#     extract_content = BeautifulSoup(program_response.content, 'html.parser')\n",
    "#     requirement_link = extract_content.select_one('#requirementstexttab a')['href']\n",
    "#     requirements_url = program_url + requirement_link\n",
    "#     requirement_response = requests.get(requirements_url)\n",
    "#     requirement_content = BeautifulSoup(requirement_response.content, 'html.parser')\n",
    "#     sections = requirement_content.select(\"h2\", {\"headerid\": \"1\", \"name\": \"requirementstext\"})\n",
    "\n",
    "\n",
    "#     course_list = requirement_content.select('.sc_courselist')\n",
    "    \n",
    "#     for course in course_list:\n",
    "#         credits = [credit.text for credit in course.select('.listsum .hourscol')]\n",
    "#         classes = [c.text.replace('\\u200b', '').replace('\\xa0', ' ') for c in course.select('.codecol')][1:]\n",
    "#         descs = [desc.text.replace('\\u200b', '').replace('\\xa0', ' ') for desc in course.select('tr .courselistcomment')]\n",
    "#         # rows = course.select('tr')\n",
    "#         # # for row in rows:\n",
    "#         # #     print(row) \n",
    "#         processed_classes = []\n",
    "#         for i, cls in enumerate(classes):\n",
    "#             if cls.startswith(\"or \"):\n",
    "#                 if processed_classes:\n",
    "#                     processed_classes[-1] += \" \" + cls\n",
    "#             else:\n",
    "#                 processed_classes.append(cls)/\n",
    "#         print(descs, processed_classes, credits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work to get schools what classes are in each school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# base_url = 'https://guide.wisc.edu'\n",
    "# start_url = 'https://guide.wisc.edu/undergraduate'\n",
    "\n",
    "# response = requests.get(start_url)\n",
    "\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# items = soup.select_one('#schoolsandcollegestextcontainer')\n",
    "# schools = items.select('li a')\n",
    "\n",
    "# schools_dict = {}\n",
    "# for school in schools:\n",
    "#     programs_list = []\n",
    "#     name = school.text\n",
    "#     school_url = base_url + school['href']\n",
    "#     school_response = requests.get(school_url)\n",
    "#     extract_content = BeautifulSoup(school_response.content, 'html.parser')\n",
    "#     requirement_link = extract_content.select_one('#degreesmajorscertificatestexttab a')['href']\n",
    "#     requirements_url = school_url + requirement_link\n",
    "#     requirement_response = requests.get(requirements_url)\n",
    "#     requirement_content = BeautifulSoup(requirement_response.content, 'html.parser')\n",
    "#     school_links = requirement_content.select('.visual-sitemap a')\n",
    "#     for link in school_links:\n",
    "#         if not re.search(r'\\s*B\\.S\\.\\s*', link.text):\n",
    "#             continue\n",
    "#         programs_list.append((link.text).split(',')[0])\n",
    "#         print((link.text).split(',')[0])\n",
    "#     schools_dict[name] = programs_list\n",
    "# schools_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(list(schools_dict.items()), columns=['School', 'Department'])\n",
    "# df2 = df2.explode('Department', ignore_index=True)\n",
    "# df2.loc[34, 'Department'] = 'Industrial and Systems Engineering'\n",
    "# df2[df2['Department']=='Industrial and Systems Engineering']\n",
    "# df3 = pd.merge(df, df2, on='Department', how='left')\n",
    "# df3 = df3[['School', 'Department', 'Class', 'Credits', 'Requisites', 'Course Designation', 'Repeatable for Credit', 'Last Taught']]\n",
    "# df3.drop_duplicates()\n",
    "# df3.to_csv('testallcourses.csv')\n",
    "# # df3[df3[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
